---
title: 'OpenCoder Outsmarts StackV2 with 3X Less Data'
draft: false
date: 2024-11-11T07:38:36+00:00
slug: '202411110738-opencoder-outsmarts-stackv2'
is_tweet: true
tweet_info:
  id: '1855756978917986627'
  type: 'thread'
  is_thread: True
---



OpenCoder is an amazing work!  Itâ€™s 100% open that comes with new 960B tokens dataset RefineCode spanning 600+ programming languages. This dataset outperforms  StackV2 to achieve same perf in 3X less tokens! 

But thatâ€™s not it. ðŸ§µ <https://x.com/sivil_taram/status/1855301760770056246>

They also use new WSD schedule that I wrote about last year (studied and published independently this year). In cooldown phase, they also use high quality synthetic data inspired by Phi models from my team. All these truly pushes OpenCoder to reach new heights.

The amazing part is that everything is reproducible with open code and data! 

It comes from a team at InfTech in China that you may not heard of. 

In a strange twist of events, Chinese startups are the ones practicing and advancing open science in AI. 

They deserve huge kudos.

[Discussion](https://x.com/sytelus/status/1855756978917986627)
