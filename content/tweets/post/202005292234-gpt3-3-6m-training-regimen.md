---
title: 'GPT-3''s $3.6M Training Regimen'
draft: false
date: 2020-05-29T22:34:00+00:00
slug: '202005292234-gpt3-3-6m-training-regimen'
is_tweet: true
tweet_info:
  id: '1266392353981509632'
  type: 'post'
  is_thread: False
---



GPT-3/175B model required 3.14E23 flops of compute for training. Even at theoretical 28 TFLOPS for V100 and lowest reserved Azure pricing, this will take 355 GPU-years and cost $3.6M for a single training run!

[Discussion](https://x.com/sytelus/status/1266392353981509632)
