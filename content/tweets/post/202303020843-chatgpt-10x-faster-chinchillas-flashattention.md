---
title: 'Chinchillas and Flashy Attention: How ChatGPT Got 10X Faster'
draft: false
date: 2023-03-02T08:43:54+00:00
slug: '202303020843-chatgpt-10x-faster-chinchillas-flashattention'
is_tweet: true
tweet_info:
  id: '1631092932920119296'
  type: 'post'
  is_thread: False
---



A lot of people are being surprised by ChatGPT inference cost being 10X smaller than GPT3 but the field had many many advances for past 2 years. 

Top 2 are:

1. Chinchilla already showed 2.5X reduction in model size for GPT3.

2. Using FlashAttention adds another 5-6X gain.

[Discussion](https://x.com/sytelus/status/1631092932920119296)
