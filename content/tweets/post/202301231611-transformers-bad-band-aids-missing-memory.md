---
title: 'Transformers: Bad Band-Aids and Missing Memory'
draft: false
date: 2023-01-23T16:11:49+00:00
slug: '202301231611-transformers-bad-band-aids-missing-memory'
is_tweet: true
tweet_info:
  id: '1617434916307992577'
  type: 'post'
  is_thread: False
---



Monthly paper reminder that Transformer architecture is still a stop-gap solution. Here authors create tasks to test generalization of formal language and find that positional encoding is a bad band-aid and augmented memory is dearly missing.

<https://arxiv.org/abs/2207.02098>

[Discussion](https://x.com/sytelus/status/1617434916307992577)
