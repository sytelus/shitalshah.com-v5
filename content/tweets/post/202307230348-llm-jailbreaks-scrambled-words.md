---
title: 'LLM Jailbreaks: Scrambled Words, Still Served Hot'
draft: false
date: 2023-07-23T03:48:20+00:00
slug: '202307230348-llm-jailbreaks-scrambled-words'
is_tweet: true
tweet_info:
  id: '1682855118088151042'
  type: 'post'
  is_thread: False
---



Jailbreaks are amazing window into LLMs. Brilliant hacks like below gives a lot of things think about:

- Is conventional tokenization really needed at GPT scale given it can still process scrambled queries like below?

- Is random ware code de novo given training data cleaning? <https://x.com/lauriewired/status/1682825103594205186>

[Discussion](https://x.com/sytelus/status/1682855118088151042)
