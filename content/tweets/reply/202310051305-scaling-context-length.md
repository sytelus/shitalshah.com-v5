---
title: 'Scaling Context Length: The Long and Short of It'
draft: true
date: 2023-10-05T13:05:10+00:00
slug: '202310051305-scaling-context-length'
is_tweet: true
tweet_info:
  id: '1709811949599707612'
  type: 'reply'
  is_thread: False
---



{{< tweet user="abacaj" id="1709811227541561679" >}}

Authors says this scaling applies to training as well as inference. As long as you can add more compute, context length can be increased *linearly* to the device count. I think this is pretty huge leap for video generation and in-context learning.

[Discussion](https://x.com/sytelus/status/1709811949599707612)
