---
title: 'Can LLaMA''s 3 Tricks Make NanoGPT Gallop?'
draft: true
date: 2023-03-29T10:16:30+00:00
slug: '202303291016-llama-nanogpt-tricks'
is_tweet: true
tweet_info:
  id: '1640915809768980480'
  type: 'reply'
  is_thread: False
---



{{< tweet user="_willfalcon" id="1640755449979863045" >}}

[@LightningAI](https://x.com/LightningAI) I am bit confused. Is this reimplementation of 3 architectural improvements in LLaMA paper to NanoGPT code base? 

What model sizes have you trained? On how many tokens? 

Is this weight compatible to original LLaMA? 

Thanks!

[Discussion](https://x.com/sytelus/status/1640915809768980480)
