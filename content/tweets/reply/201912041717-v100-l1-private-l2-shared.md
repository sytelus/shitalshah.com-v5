---
title: 'V100 SMs Keep L1 Private, But Share L2 Love'
draft: true
date: 2019-12-04T17:17:45+00:00
slug: '201912041717-v100-l1-private-l2-shared'
is_tweet: true
tweet_info:
  id: '1202155015873282051'
  type: 'reply'
  is_thread: False
---



{{< tweet user="srchvrs" id="1202110584633921538" >}}

For V100 L1 is private to each streaming multiprocessor (total of 80) while L2 (~ 6MB) is shared between them. This has pretty good explanation: <https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html>

[Discussion](https://x.com/sytelus/status/1202155015873282051)
