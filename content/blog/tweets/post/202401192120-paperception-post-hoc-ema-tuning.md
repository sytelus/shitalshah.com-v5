---
title: 'Paperception: Unveiling Post-Hoc EMA Tuning'
draft: false
date: 2024-01-19T21:20:35+00:00
slug: '202401192120-paperception-post-hoc-ema-tuning'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1748334639394202071'
  type: 'post'
  is_thread: False
---



Here is a paper hidden inside a paper! As many folks doing LLM training knows EMA can improve models significantly but tuning EMA is hard because runs themselves are very expensive. Here authors have figured out how to do it post-hoc!
<https://arxiv.org/abs/2312.02696>

[Discussion](https://x.com/sytelus/status/1748334639394202071)
