---
title: 'One Ring to Train Them All: Scaling Transformers with Ring Attention'
draft: false
date: 2023-10-05T12:59:46+00:00
slug: '202310051259-one-ring-to-train-them-all'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1709810589902786613'
  type: 'post'
  is_thread: False
---



Groundbreaking work! “Our experiments show that Ring Attention can reduce the memory requirements of Transformers, enabling us to train more than 500 times longer sequence than prior memory efficient state-of-the-arts and enables the training of sequences that exceed 100 million… <https://x.com/haoliuhl/status/1709630382457733596>

[Discussion](https://x.com/sytelus/status/1709810589902786613)
