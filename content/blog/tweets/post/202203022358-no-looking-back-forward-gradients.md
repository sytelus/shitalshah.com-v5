---
title: 'No Looking Back(prop): Forward Pass to Faster Gradients'
draft: false
date: 2022-03-02T23:58:28+00:00
slug: '202203022358-no-looking-back-forward-gradients'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1499051522771984385'
  type: 'post'
  is_thread: False
---



Gradients without backpropogation: This paper uses only a forward pass and forward mode auto-differentiation to compute gradient exactly, about 2X faster than backprop. 

<https://arxiv.org/abs/2202.08587>

[Discussion](https://x.com/sytelus/status/1499051522771984385)
