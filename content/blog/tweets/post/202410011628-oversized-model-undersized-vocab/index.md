---
title: 'Oversized Model, Undersized Vocab'
draft: false
date: 2024-10-01T16:28:40+00:00
slug: '202410011628-oversized-model-undersized-vocab'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1841047571122569502'
  type: 'post'
  is_thread: False
---



Scaling laws for vocab size: <https://arxiv.org/abs/2407.13623>

This paper asserts that as model gets larger, vocab size should be getting larger. Specifically, Llama2-70B vocab size is way below optimal (32K vs 216K).

However, E2E benchmark perf improvement seems underwhelming evenâ€¦ 

![https://pbs.twimg.com/media/GYy3AhwbQAQdQJ3.jpg](afyR0AY2r5.jpg)

[Discussion](https://x.com/sytelus/status/1841047571122569502)
