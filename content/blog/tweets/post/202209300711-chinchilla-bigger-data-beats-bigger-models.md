---
title: 'Chinchilla''s Lesson: Bigger Data Beats Bigger Models'
draft: false
date: 2022-09-30T07:11:51+00:00
slug: '202209300711-chinchilla-bigger-data-beats-bigger-models'
is_tweet: true
tweet_info:
  id: '1575639525828997120'
  type: 'post'
  is_thread: False
---



The main insight here is that you can get same quality as 175B param model in 30B param model by increasing dataset size (per Chinchilla paper that showed GPT was not trained compute efficiently). The cost reduction for training then follows due to reduced compute. <https://x.com/NaveenGRao/status/1575589170709291008>

[Discussion](https://x.com/sytelus/status/1575639525828997120)
