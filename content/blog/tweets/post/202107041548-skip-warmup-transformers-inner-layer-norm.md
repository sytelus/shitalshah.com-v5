---
title: 'Skip the Warm-up: Transformers with Inner Layer Norm'
draft: false
date: 2021-07-04T15:48:25+00:00
slug: '202107041548-skip-warmup-transformers-inner-layer-norm'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1411607820542218245'
  type: 'post'
  is_thread: False
---



If the layer normalization is put inside the residual blocks, warm-up stage is not required for transformers:
<http://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf>

[Discussion](https://x.com/sytelus/status/1411607820542218245)
