---
title: 'Phi-3 14B: Small Model, Big MMLUâ€”Rivaling Llama3 70B!'
draft: false
date: 2024-05-22T10:45:21+00:00
slug: '202405221045-phi3-14b-challenges-llama3-70b'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1793125973090832765'
  type: 'post'
  is_thread: False
---



Phi-3 14B model from our team is available now! This was trained with 512 H100s on 4.8T tokens achieving MMLU of 78 (comparable with Llama3 70B!!).

<https://huggingface.co/microsoft/Phi-3-medium-4k-instruct>

[Discussion](https://x.com/sytelus/status/1793125973090832765)
