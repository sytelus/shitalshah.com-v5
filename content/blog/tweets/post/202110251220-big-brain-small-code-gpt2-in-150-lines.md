---
title: 'Big Brain, Small Code: GPT-2 in 150 Lines'
draft: false
date: 2021-10-25T12:20:38+00:00
slug: '202110251220-big-brain-small-code-gpt2-in-150-lines'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1452505360846057475'
  type: 'post'
  is_thread: False
---



GPT2 and training it, all in less than 150 lines of code:

<https://gist.github.com/thomwolf/ca135416a30ea387aa20edaa9b21f0ed>

[Discussion](https://x.com/sytelus/status/1452505360846057475)
