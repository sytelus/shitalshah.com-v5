---
title: 'LLMs in a Flash: 8x Speed Boost with Flash-Decoding'
draft: true
date: 2023-10-14T05:27:11+00:00
slug: '202310140527-llms-in-a-flash'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1712958184376439211'
  type: 'retweet'
  is_thread: False
---



RT [@tri_dao](https://x.com/tri_dao): Announcing Flash-Decoding, to make long-context LLM inference up to 8x faster! Great collab with [@d_haziza](https://x.com/d_haziza), [@fvsmassa](https://x.com/fvsmassa) and Grigâ€¦ [continue reading](https://x.com/sytelus/status/1712958184376439211)
