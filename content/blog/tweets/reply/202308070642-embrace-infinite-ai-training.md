---
title: 'Don''t Roll the Dice: Embrace Infinite AI Training'
draft: true
date: 2023-08-07T06:42:52+00:00
slug: '202308070642-embrace-infinite-ai-training'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1688334856345079809'
  type: 'reply'
  is_thread: False
---



{{< tweet user="BlancheMinerva" id="1688322001885413376" >}}

[@__kolesnikov__](https://x.com/__kolesnikov__) [@giffmana](https://x.com/giffmana) I doubt 20k is constant for all model/token sizes. We really need more theoretical work on this. When you are deciding 200k steps, you are rolling a dice. It would be good to have option to continue training indefinitely as and when more compute and/or data becomes available.

[Discussion](https://x.com/sytelus/status/1688334856345079809)
