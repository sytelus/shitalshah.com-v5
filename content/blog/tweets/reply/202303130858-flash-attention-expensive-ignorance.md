---
title: 'Flash Attention: Stop Living in Expensive Ignorance'
draft: true
date: 2023-03-13T08:58:17+00:00
slug: '202303130858-flash-attention-expensive-ignorance'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1635097919962619907'
  type: 'reply'
  is_thread: False
---



{{< tweet user="abacaj" id="1635075279466147840" >}}

First two have pro and cons but Flash Attention is used extensively. Most latest diffusion models use Flash Attention which is why they can run on small GPUs at all. If you are training without Flash Attention in 2023 then you are living in very expensive ignorance.

[Discussion](https://x.com/sytelus/status/1635097919962619907)
