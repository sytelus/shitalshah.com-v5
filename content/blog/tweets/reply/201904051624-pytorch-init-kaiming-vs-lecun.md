---
title: 'Kaiming in, LeCun out: PyTorch 1.0''s Sneaky Init Swap'
draft: true
date: 2019-04-05T16:24:25+00:00
slug: '201904051624-pytorch-init-kaiming-vs-lecun'
tags:
  - tweets
is_tweet: true
tweet_info:
  id: '1114096444359581696'
  type: 'reply'
  is_thread: False
---



{{< tweet user="jeremyphoward" id="1113693905172623361" >}}

[@rasbt](https://x.com/rasbt) I believe Pytorch 1.0 uses Kaiming uniform init as default for conf and linear layers. The  0.4.1 used to do something akin to LeCunn init.

[Discussion](https://x.com/sytelus/status/1114096444359581696)
